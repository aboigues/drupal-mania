# Configuration Fluentd pour Drupal-Mania
# Collecte des logs de Drupal et PostgreSQL vers Elasticsearch

# Source: écoute des logs Docker via forward
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Filtre: Parser les logs Drupal
<filter drupal>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type regexp
    expression /^\[(?<timestamp>[^\]]+)\] (?<level>\w+): (?<message>.*)$/
    time_key timestamp
    time_format %Y-%m-%d %H:%M:%S
  </parse>
</filter>

# Filtre: Parser les logs PostgreSQL
<filter postgres>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type regexp
    expression /^(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3} \w+) \[(?<process_id>\d+)\] (?<level>\w+):  (?<message>.*)$/
    time_key timestamp
    time_format %Y-%m-%d %H:%M:%S.%N %Z
  </parse>
</filter>

# Filtre: Ajouter des métadonnées
<filter **>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    environment "${ENVIRONMENT:-production}"
    project "drupal-mania"
  </record>
</filter>

# Output: Envoyer vers Elasticsearch
<match **>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix drupal-mania
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  tag_key @log_name
  flush_interval 10s

  <buffer>
    @type file
    path /fluentd/log/buffer
    flush_mode interval
    retry_type exponential_backoff
    flush_thread_count 2
    flush_interval 10s
    retry_forever false
    retry_max_interval 30
    chunk_limit_size 2M
    queue_limit_length 8
    overflow_action block
  </buffer>
</match>
